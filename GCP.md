# Test1

## BigQuery

- 準リアルタイムである程度複雑な SQL クエリが可能

- 破損の検出が 7 日以内の場合、過去の時点のテーブルに対してクエリを行い、スナップショット デコレータを使ったクエリで破損前のテーブルからクエリして復元
- オンライン分析処理（OLAP）システムでのインタラクティブなクエリが必要な場合は、BigQuery を検討してください。

## BigTable

- NoSQL
- key-value
- リアルタイムだが、SQL クエリは実行できない
- 低レイテンシでスケーラブル
- GoogleMap, Gmail, IoT..etc
- Goolgle のコアサービスを支える大規模分散データベース
- 並列処理が求められる大規模データが得意
- ACID トランザクションのサポートが不要な場合、またはデータが高度に構造化されていない場合は、Cloud Bigtable を検討してください。

## DataStore

- DataStore モードの FireStore(将来的に統合)
- NoSQL に分類されるが、SQL が使える。
- 高可用性が求められる大規模な構造化データが得意
- ACID トランザクション
- インデックスも使える
- 最大の特徴は、アプリケーション負荷に応じてシームレスに自動スケーリングする ⇒ 　スケールアウト！トランザクションが必要で、かつユーザーが増えそうなアプリとか(CloudSQL はスケールアップのみ!)
- シャーディング（データの複数サーバへの分散）、レプリケーション（複数サーバでのコピー）も自動
- 強整合性と結果整合性のバランス

## CloudSQL

- SQL を完全にサポートするオンライン トランザクション処理（OLTP）システム向けのリレーショナル データベースが必要な場合は、Cloud SQL を検討してください。
- Max30TB
- 自動スケールアップ ※スケールアウトではない！
- リージョナル ⇔ Spanner はグローバル
- HA 構成をとれる。HA 構成はクラスタとも呼ばれる。HA 構成の CloudSQL インスタンスは「リージョンインスタンス」といい、プライマリゾーンとセカンダリゾーンにプライマリインスタンスとスタンバイインスタンスとして配置される。ゾーン障害時にはフェイルオーバーされる。

## CloudStorage

大容量の画像やムービーなど、大規模な不変 blob を格納する必要がある場合は、Cloud Storage を検討してください。

## Transfer Appliance

- 大容量のストレージ デバイス
- 大容量データのクラウド移行で、アウトバウンドネットワーク帯域が少ない場合
- 小さいデータの場合、gsutil cp
- 大きいデータや、クラウドを跨ぐ転送の場合、Storage Transfer Service
  - お好みの言語で Storage Transfer API やクライアント ライブラリを使用して、転送ジョブの作成と管理を自動化できます。GSUTIL と比較すると、Storage Transfer Service は再試行を処理し、詳細な転送ロギングを提供するマネージド ソリューション

## 強整合性と結果整合性

- 強整合性 の場合、データの更新の際にデータベースをロックすることによってデータの一貫性（Consistency）を担保するが、ロックされる期間が長いほどその間のデータベース・アクセスがブロックされ、可用性（Availability）を犠牲にすることになる
- 結果整合性 はデータの更新でデータベースがロックされることはないため、可用性とスケーラビリティを維持することができる。その代わりノード間でのデータの一貫性は必ずしも担保されない

## BigQuery のオーソライズドビュー

承認済みビュー。通常のビューではソースとなるテーブルへのアクセス権限も付与する必要があるが、承認済みビューではソーステーブルへの権限なしで特定のユーザーやグループと共有できる。

## DataPrep / DataProp / DataFlow / CloudComposer

- DataPrep は探索的なデータ探索、加工、ロードを可能にするデータプレパレーションサービス。GUI 操作でデータクレンジングを直観的に行う。処理エンジンには DataFlow、Python、BigQuery が利用される。
- DataProc はマネージド Hadoop/Spark クラスタ
- DataFusion は GUI 操作できるデータ統合プラットフォームサービス。 DataProc クラスタが一時的リソースとして立ち上がり、ジョブが終了すると削除される。
- DataFlow は ApacheBeam をベースにしたストリーム/バッチの分散データ処理パイプラインのマネージド版。オートスケール対応で重い処理や複雑な処理に向いている
  - PCollection
    - パイプライン データとして機能する複数要素のデータセット
  - Transform
    - 1 つ以上の PCollection を入力として受け取り、そのコレクションの各要素に対して指定したオペレーション(=ParDo)を実行して、1 つ以上の PCollection を出力
  - ParDo
    - 入力 PCollection の [各要素] に対してユーザー指定の関数を呼び出し、0 個以上の出力要素を 1 つの出力 PCollection に収集
    - Apache Beam SDK のコア並列処理オペレーション

## Pub/Sub の配信モデル

- at-least once 配信モデルなので、メッセージ重複を考慮する必要がある。サブスクライバーとなるアプリケーションでは冪等性が保証される設計・実装を行う必要がある。exactly once 配信モデルは CloudDataFlow などを利用して重複排除の仕組みを実装することで実現可能。
- 順序制御は順序指定オプションを有効化
- テッドレタートピックを設定すると、正しく配信できずにリトライ上限に達したメッセージをデッドレタートピックに転送できる

## DataLossPrevention(DLP)

- Cloud DLP は、Cloud Storage、BigQuery、Cloud Datastore の機密データのスキャンと分類をネイティブにサポートし、ストリーミングコンテンツ API により、追加のデータソース、カスタムワークロード、アプリケーションへ適用可能。データセキュリティとプライバシーのレイヤーを追加してデータワークロードに組み込むことにより、機密データを保護することができます。また、Cloud Storage や BigQuery などのストレージリポジトリにあるデータの大規模な検査、発見、分類のためのネイティブサービスも提供します。

## Dataproc

- プリエンプティブル VM
  Dataproc クラスタは、標準的な Compute Engine VM を Dataproc ワーカー（「プライマリ」ワーカーと呼びます）として使用するだけでなく、「セカンダリ」ワーカーも使用できます。プリエンプティブル VM(セカンダリワーカーのデフォルト) は、通常のインスタンスよりはるかに低価格で作成、実行できるインスタンスです。ただし、他のタスクがリソースへのアクセスを必要とする場合、Compute Engine がこのインスタンスを停止（プリエンプト）する可能性があります。プリエンプティブル インスタンスは Compute Engine の余剰のキャパシティを利用する機能であり、使用できるかどうかは利用状況に応じて異なります。

- Dataproc はストレージに Hadoop 分散ファイル システム（HDFS）を使用する
  また、HDFS 互換の Cloud Storage コネクタが自動的にインストールされるため、HDFS と並行して Cloud Storage も使用できます。
  クラスタに対してデータの移動を行うには、HDFS や Cloud Storage へのアップロードとダウンロードを使用する。
  ⇒ ホットデータは HDFS に残して、、とかでなく、すべて CloudStorage に移すなどもコスト考えるといい!
  ⇒ Dataproc と GCS を Google Cloud Storage のコネクタで接続すると、クラスタの寿命が来た後もデータを保存することができる！

ベストプラクティスとして MapReduce ジョブは、一つの目的に対して一つ作成されるべきで、モノリシック化されるべきではありません。
今回の例であれば、既存のジョブは数日かかるため、仮にこのジョブにキャリブレーションを追加すると、テスト自体に多くの工数がかかりますし、メンテナンス容易性が低下する。

つまり、キャリブレーションの処理を追加する際は、新たに MapReduce ジョブを追加する必要があります。

- 水平スケーリング
  Dataproc のようなバッチの場合は、コンピューティングリソースが時間課金という特性を活かして、水平スケーリングを積極的に活用するべきです

- Apache Beam では、データ分析のためのエンリッチメントを行う際には、「サイドインプットパターン」が推奨されています。

- 高度な柔軟性モード(EFM)
  スケールダウンやプリエンプションのためにワーカーノードを削除すると、ノードに保存されているシャッフル(中間データ)が失われる可能性がある。
  プリエンプティブル VM を使用したり、自動スケーリングの安定性を改善したい場合は、高度な柔軟性モードを有向にすることが推奨される。
  ⇒ CloudDataFlow のドレインと似ている

## 同期/非同期レプリケーション,CloudSQL の HA 構成とフェイルオーバ

- Cloud SQL インスタンスは高可用性（HA）構成をとることができます。
- HA 構成は「クラスタ」とも呼ばれ、データの冗長性を確保します。HA 向けに構成された Cloud SQL インスタンスは「リージョン インスタンス」とも呼ばれ、構成されたリージョン内のプライマリ ゾーンとセカンダリ ゾーンに配置されます。
  Cloud SQL のオプションはリージョナルで、Cloud Spanner に比べてスケーラビリティが小さくなります。
  Cloud SQL は確約利用割引（CUD）が使える。特定のリージョンで、データベース インスタンスの 1 年間または 3 年間にわたる継続的な使用の確約と引き換えに適用される、大幅な割引料金。

- リージョン インスタンスはプライマリ インスタンス(プライマリゾーン)とスタンバイ インスタンス(セカンダリゾーン)で構成されます。各ゾーンの永続ディスクへ同期レプリケーション複製される。

  - 高可用性のためにレプリケーションを使っているときに、マスタでデータを更新した直後にマスタがダウンしたとすると、そのトランザクションの commit データがスレーブに複製されておらず、データ更新自体が失われてしまうこともあるかもしれません。
  - 非同期レプリケーションでは、マスタの更新内容は速やかにスレーブに反映されますが、タイミングによってはマスタとスレーブでデータの内容が異なりますし、また、マスタがデータ更新の直後にダウンすると、データ更新が失われる可能性もあります。
  - 一方で、同期レプリケーションでは、スレーブにデータ更新が反映されるのをマスタが待つので、更新性能がややダウンすることになりますが、マスタとスレーブのデータの内容は常に同じになりますし、マスタがダウンしてもデータ更新が失われることはありません。

- インスタンスまたはゾーンで障害が発生した場合、永続ディスクはスタンバイ インスタンスにアタッチされ、新しいプライマリ インスタンスになります。ユーザーは新しいプライマリに再転送されます。このプロセスは、フェイルオーバーと呼ばれます。

[ref](https://cloud.google.com/sql/docs/mysql/high-availability)

## Dataflow ジョブは、二つの方法で停止することが可能です

- ジョブをキャンセルする：
  この方法は、ストリーミング パイプラインとバッチ パイプラインの両方に適用されます。ジョブをキャンセルすると、Dataflow サービスはバッファデータなどのデータの処理を停止します。
- ジョブをドレインする：
  この方法は、ストリーミング パイプラインにのみ適用されます。ジョブをドレインすると、Dataflow サービスはバッファ内のデータの処理を完了すると同時に、新しいデータの取り込みを中止できます。
  ⇒ DataProc の高度な柔軟性モード(EFM)と似ている

## アクセス制御リスト（ACL）

細かく設定したい場合。ほとんどの場合は IAM で事足りる

BigQuery テーブル ACL では、テーブルやビューなどのリソースにテーブルレベルの権限を設定できます。
テーブルレベルの権限により、データまたはビューにアクセスできるユーザー、グループ、サービス アカウントが決まります。
ユーザーに完全なデータセットへのアクセス権を与えることなく、特定のテーブルまたはビューへのアクセス権を付与できます。

## 確認応答期限が切れる前にメッセージの確認応答を行わないと、Pub/Sub によってメッセージが再送信されます

その結果、Pub/Sub によって重複するメッセージが送信されることがあります。
Google Cloud のオペレーション スイートを使用して、expired レスポンス コードで確認応答オペレーションをモニタリングし、この状態を検出する。

## 主キーを選択する上で重要な点は、ホットスポットを回避するという点です

単調増加する値やエポックタイムなどは、ホットスポットを発生させる可能性があるため不適切です。
代わりに、キーのハッシュ値や UUID などのランダムな値を用いることは、ベストプラクティスです。
→Bigtable などでも、ホットスポットは処理を集中させ、パフォーマンス低下させるらしい。分散処理なので、多くのノードを効率よく使わないといけないのだろう。なので、処理する行はテーブル全体に分散していた方がいい。

クラスタに保存されるデータ量が増加すると、Bigtable はクラスタ内のすべてのノードにデータを分散してストレージを最適化します。データを継続的に保存し続けるためには、使用率が増大していることはいち早く検知する必要があります。
→ Bigtable の場合、データ使用量の増大がパファーマンス低下を招く！

## Cloud Monitoring では、ネットワーク接続、ディスク ID、レプリケーションの状態などのカスタムメトリクスはデフォルトで収集することができません

従って、オーバーヘッドの少ない方法で、VM からカスタムメトリクスを収集するためのツールをインストールする必要があります。
Google Cloud では、OpenCensus を使ったカスタムメトリクスの収集が推奨されています。
OpenCensus は無料のオープンソース プロジェクトで、次のことが可能になります。

- メトリクスおよびトレースデータをさまざまな言語で収集するための、ベンダーに依存しないサポートを提供できます。
- 収集したデータを、Cloud Monitoring を含むさまざまなバックエンド アプリケーションにエクスポートできます。

## HBase

HBase は、Google のビッグテーブルに似た NoSQL データモデルで、膨大な量の構造化データへの迅速なランダムアクセスを実現するために設計されました。
Hadoop File System （HDFS）が提供するフォールトトレランスを利用しています。
HDFS は Hadoop エコシステムの一部であり、Hadoop File System 内のデータに対してランダムなリアルタイムリード/ライトアクセスを提供する。
HDFS には、直接または HBase を介してデータを格納することができます。
データ消費者は、HBase を使用して HDFS のデータをランダムに読み取り、アクセスする。HBase は Hadoop File System の上に置かれ、読み取りと書き込みのアクセスを提供する。

HBase は、大量データに対応した分散ストレージシステム。Cassandra、Redis、MongoDB などと同じで、NoSQL データベース

## Apache casandra

Cassandra は 2007 年 Facebook 社のエンジニアによって開発されました。
その後 Apache Software Foundation のプロジェクトとなり、成長を続け 2017 年 2 月にバージョン 3.10 がリリースされました。
NoSQL というと、少し取りつきにくいイメージもありますが、Cassandra は　テーブルにデータを格納し CQL という SQL のようなクエリ言語を利用してデータのやりとりをすることができるため、直観的にはリレーショナル DB を使っているかのように操作ができます。
Cassandra は、複数台でクラスターを組んで分散 DB を作成し、スケールアウトすることが容易にできる構造になっています。また処理性能も構成するノード数に比例します。
そのためサーバー管理者としては、比較的安価にスケーラビリティを確保できます。

「Apache HBase はオープンソースの、列指向、分散データベースであり、Google の BigTable をモデルとし、Java により書かれている。
Apache Hadoop」（以降、Hadoop）は、デファクトスタンダードになっているビッグデータ向けの処理基盤です。HBase は Hadoop のエコシステムを構成する OSS の 1 つで、Hadoop の分散ファイルシステムである HDFS 上に構築する分散データベースです。

## スロット

BigQuery スロットは、BigQuery で SQL クエリを実行するために使用される仮想 CPU です。BigQuery では、クエリのサイズと複雑さに応じて、クエリに必要なスロット数が自動的に計算されます。

オンデマンド料金モデルまたはフラットレート料金モデルのいずれかを選択できます。どちらも、データ処理にスロットを使用します。フラットレート モデルではスロットと分析容量を明示的に制御できますが、オンデマンド モデルではできません。

フラットレート料金モデルのお客様は、予約するスロットの数を明示的に選択します。クエリはその容量内で実行され、デプロイされる 1 秒ごとに容量に対して継続的に支払います。たとえば、BigQuery スロットを 2,000 購入した場合、集計したクエリはいつでも 2,000 仮想 CPU のみに制限されます。この容量はそれを解除するまで保持され、集計したクエリを削除するまで 2,000 スロットに対して支払います。

BigQuery オンデマンド料金モデルのプロジェクトには、一時的なバースト容量を備えたプロジェクトごとのスロットの割り当てが適用されます。オンデマンド モデルを使用するほとんどのユーザーにとって、デフォルトで割り当てられるスロットの容量は十分です。ワークロードによっては、より多くのスロットにアクセスできるようにすることでクエリ パフォーマンスが向上します。アカウントで使用しているスロットの数を確認するには、BigQuery のモニタリングをご覧ください。

⇒ 要するに CPU スロットのこと。あらかじめ決まったスロットの上限内で CPU リソースを使って、クエリが実行される

多くのスロットを予約すると、BigQuery スロットの可用性は確保されますがパフォーマンスは向上しません。

⇒ スロット増やしてもパフォーマンス上がるわけではない！

## 定額制

プロジェクトを新しく作らないという条件で、最適なクエリスロットルを確保する必要があります。

今回のケースであれば、定額制の料金モデルを採用することが最適です。

このモデルでは、一定数のスロットがお客様のプロジェクトに割り当てられ、プロジェクト間で階層的な優先順位モデルを確立することができます。

定額制は、複数の事業部門があり、優先順位や予算が異なるワークロードを抱える大企業に特に適しています。

したがって、正解は「定額制に切り替え、プロジェクトの優先順位を階層的に設定する」です。

## BigQuery のマテリアライズドビューは頻繁に更新される小さなデータセットに向いている

マテリアライズド ビューは、パフォーマンスを向上させるためにクエリの結果を定期的にキャッシュ保存します。マテリアライズド ビューは、頻繁にクエリされる小さなデータセットに適しています。基盤となるテーブルデータが変更されると、影響を受ける部分をマテリアライズド ビューが無効化して再度読み込みます。
→ 勝手に、しかも対象の箇所だけ！更新される！

## Cloud Spannar はリレーショナル！グローバルスケールで、インターリーブによるパフォーマンス向上をサポート

リレーショナル データベースでは、非正規化は好ましい手法ではありません。繰り返しデータにより複数の行が発生するためです。

Cloud Spanner ではインターリーブと呼ばれる、あるテーブルのレコードの物理的な配置を別のテーブルのレコードの配下に置ける仕組みがあります。この仕組みを使ってテーブル間に親子関係を作ることで、複数のテーブル間に参照整合性制約を持たせたり、パフォーマンスを向上させることができます。
Cloud Spanner では SELECT AS STRUCT 構文をサブクエリに使うことで、親のテーブルとインターリーブされたテーブルのレコードを一発で高速に取得することができます。更に Cloud Spanner の CPU 使用率も抑えることができるので非常に効率的にクエリできます。

選択肢 B は正解です。Cloud Spanner は、リレーショナル データをサポートする、グローバル スケールで高可用性のデータベースを提供します。

C: 選択肢 C は不正解です。Cloud SQL のオプションはリージョナルで、Cloud Spanner に比べてスケーラビリティが小さくなります。

※BigQuery もグローバルスケールではない。

## Cloud SQL は確約利用割引（CUD）が使える。

特定のリージョンで、データベース インスタンスの 1 年間または 3 年間にわたる継続的な使用の確約と引き換えに適用される、大幅な割引料金。

## BigQuery のカスタム割り当て

BigQuery プロジェクトとユーザーが複数ある場合は、1 日あたりに処理されるクエリデータの量に上限を指定するカスタム割り当てをリクエストして、コストを管理できます。

## Cloud Interconnect

Cloud Interconnect は、低レイテンシで高可用性の接続を実現することにより、オンプレミス ネットワークと Google Cloud Virtual Private Cloud（VPC）ネットワーク間での安定したデータ転送を可能にします。また、Interconnect 接続により内部 IP アドレス通信も実現し、これにより双方のネットワークから内部 IP アドレスに直接アクセスできます。

Cloud Interconnect には、オンプレミス ネットワークを拡張するための 2 つのオプションがあります。
Dedicated Interconnect は、オンプレミス ネットワークと Google のネットワークを物理的に直接接続します。
Partner Interconnect は、サポート対象のサービス プロバイダを介して、オンプレミス ネットワークと VPC ネットワークを接続します。
⇒ intercommect だと、公共のネットワークを通過しない。

Cloud Interconnect の低レイテンシと高可用性を必要としない場合は、Cloud VPN を使用してネットワーク間で IPsec VPN トンネルをセットアップすることを検討してください。IPsec VPN トンネルは、トラフィックが公共のインターネットを通過する際に、業界標準の IPsec プロトコルを使用してデータを暗号化します。

Cloud VPN トンネルを使用すれば、直接のプライベート接続に付随するオーバーヘッドやコストの必要がなくなります。Cloud VPN で必要となるのは、オンプレミス ネットワークに VPN デバイスを配備することだけです。

## AutoML は転移学習できるのが強み！

データ量が比較的少なく多様なため、このデータのみでは構築されたモデルの精度は低くなります。AutoML は他の類似データに基づく転移学習を使用するため、適切です。

## Pig と Hive は、共に SQL ライクな記法で MapReduce を書ける DSL である

## MapReduce YARN Tez は Hadoop 内のアルゴリズム。

YARN は MR より明らかに優れる。Tez は YARN における並列処理エンジンについて、MR の代わりを目指している

## BigQuery では GeoJson 形式をサポートしている。

インタラクティブな可視化も簡単。地理空間分析では、地理データ型と標準の SQL 地理関数を使用して、BigQuery で地理空間データを分析し、可視化できます。

## ウォーターマーク/トリガー

ウォーターマーク
ウィンドウにつけるタイムスタンプを基にした目印
データの遅延などを見つける
パイプラインに到着したとシステムが見なすタイミングのことです。
ウォーターマークを超えて到着したデータは遅延データとして扱われます。Dataflow は最適なウォータマークを学習します。左側の図は遅延データがくるまで待機し、右の図は Dataflow の予測に基づいたウォーターマークです。この場合、遅延データは計算に考慮されません。

トリガー
データが到着したときに集計結果をいつ出力するかを決定する
デフォルトでは、ウォーターマークを基に決定される

## RPC は同期呼び出し！名前がそう。

Pub/sub はそれを分離する。非同期呼び出し

## OLAP キューブ

データの多次元配列。Online Analytical Processing（OLAP）は、洞察のためにデータを分析するコンピューターベースの手法。
キューブとは、多次元データセットを指し、次元数が 3 より大きい場合、ハイパーキューブとも呼ばれる。
